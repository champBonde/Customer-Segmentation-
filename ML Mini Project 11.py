# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G3YcLYSYSMANy6223ZdlP8rBLlGFwyT5
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

def load_dataset(csv_path=r"/content/ML Mall_Customers_Dataset.csv"):
    # Load CSV and skip initial description rows
    try:
        df = pd.read_csv(csv_path, skiprows=2)
        # The first valid row after skipping 2 rows becomes the header row
        df.columns = df.iloc[0]  # set row 0 as header
        df = df[1:]  # drop the header row itself
        df = df.reset_index(drop=True)

        # Clean up column names
        df.columns = [str(c).strip() for c in df.columns]

        # Convert numeric columns
        df["Annual Income (k$)"] = pd.to_numeric(df["Annual Income (k$)"], errors='coerce')
        df["Spending Score (1-100)"] = pd.to_numeric(df["Spending Score (1-100)"], errors='coerce')
        df = df.dropna(subset=["Annual Income (k$)", "Spending Score (1-100)"])

        return df
    except Exception as e:
        raise RuntimeError(f"Error reading dataset: {e}")

def do_kmeans(df, n_clusters=5):
    X = df[['Annual Income (k$)', 'Spending Score (1-100)']].astype(float)

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    # Elbow method
    wcss = []
    for k in range(1, 8):
        km = KMeans(n_clusters=k, init='k-means++', n_init=10, random_state=42)
        km.fit(X_scaled)
        wcss.append(km.inertia_)

    plt.figure(figsize=(6,4))
    plt.plot(range(1,8), wcss, marker='o', linestyle='--')
    plt.title('Elbow Method (1–7 Clusters)')
    plt.xlabel('Number of clusters (k)')
    plt.ylabel('WCSS (inertia)')
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Final KMeans
    kmeans = KMeans(n_clusters=n_clusters, init='k-means++', n_init=10, random_state=42)
    labels = kmeans.fit_predict(X_scaled)
    df = df.copy()
    df['Cluster'] = labels

    # Cluster Plot
    plt.figure(figsize=(7,5))
    for cluster in range(n_clusters):
        mask = labels == cluster
        plt.scatter(X_scaled[mask, 0], X_scaled[mask, 1], s=60, label=f'Cluster {cluster+1}')
    centers = kmeans.cluster_centers_
    plt.scatter(centers[:,0], centers[:,1], s=200, marker='X', edgecolor='k', linewidth=1.2, label='Centroids')
    plt.title('Customer Segments (scaled features)')
    plt.xlabel('Annual Income (scaled)')
    plt.ylabel('Spending Score (scaled)')
    plt.legend()
    plt.tight_layout()
    plt.show()

    return df, kmeans, scaler

if __name__ == "__main__":
    dataset_path = r"/content/ML Mall_Customers_Dataset.csv"
    df = load_dataset(dataset_path)
    print("✅ Dataset Loaded Successfully:")
    print(df.head())

    clustered_df, kmodel, scaler = do_kmeans(df, n_clusters=5)
    print("\nCluster counts:")
    print(clustered_df['Cluster'].value_counts().sort_index())

    clustered_df.to_csv("Mall_Customers_Clustered.csv", index=False)
    print("\n✅ Clustered data saved to 'Mall_Customers_Clustered.csv'.")